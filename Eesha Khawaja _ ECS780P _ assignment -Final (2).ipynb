{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292cf029-56d0-4430-b3bf-75e3d1b210c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import ipywidgets as wdg\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87abc469-d694-4780-b667-abe31e9b4ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this API wrapper is inserted from week 10 explanations, it will enable me to access all the data in my API. \n",
    "\n",
    "class APIwrapper:\n",
    "    # class variables shared among all instances\n",
    "    _access_point=\"https://api.ukhsa-dashboard.data.gov.uk\"\n",
    "    _last_access=0.0 # time of last api access\n",
    "    \n",
    "    def __init__(self, theme, sub_theme, topic, geography_type, geography, metric):\n",
    "        \"\"\" Init the APIwrapper object, constructing the endpoint from the structure\n",
    "        parameters \"\"\"\n",
    "        # build the path with all the required structure parameters. You do not need to edit this line,\n",
    "        # parameters will be replaced by the actual values when you instantiate an object of the class!\n",
    "        url_path=(f\"/themes/{theme}/sub_themes/{sub_theme}/topics/{topic}/geography_types/\" +\n",
    "                  f\"{geography_type}/geographies/{geography}/metrics/{metric}\")\n",
    "        # our starting API endpoint\n",
    "        self._start_url=APIwrapper._access_point+url_path\n",
    "        self._filters=None\n",
    "        self._page_size=-1\n",
    "        # will contain the number of items\n",
    "        self.count=None\n",
    "        print(self._start_url)\n",
    "\n",
    "    def get_page(self, filters={}, page_size=5):\n",
    "        \"\"\" Access the API and download the next page of data. Sets the count\n",
    "        attribute to the total number of items available for this query. Changing\n",
    "        filters or page_size will cause get_page to restart from page 1. Rate\n",
    "        limited to three request per second. The page_size parameter sets the number\n",
    "        of data points in one response page (maximum 365); use the default value \n",
    "        for debugging your structure and filters. \"\"\"\n",
    "        # Check page size is within range\n",
    "        if page_size>365:\n",
    "            raise ValueError(\"Max supported page size is 365\")\n",
    "        # restart from first page if page or filters have changed\n",
    "        if filters!=self._filters or page_size!=self._page_size:\n",
    "            self._filters=filters\n",
    "            self._page_size=page_size\n",
    "            self._next_url=self._start_url\n",
    "        # signal the end of data condition\n",
    "        if self._next_url==None: \n",
    "            return [] # we already fetched the last page\n",
    "        # simple rate limiting to avoid bans\n",
    "        curr_time=time.time() # Unix time: number of seconds since the Epoch\n",
    "        deltat=curr_time-APIwrapper._last_access\n",
    "        if deltat<0.33: # max 3 requests/second\n",
    "            time.sleep(0.33-deltat)\n",
    "        APIwrapper._last_access=curr_time\n",
    "        # build parameter dictionary by removing all the None\n",
    "        # values from filters and adding page_size\n",
    "        parameters={x: y for x, y in filters.items() if y!=None}\n",
    "        parameters['page_size']=page_size\n",
    "        # the page parameter is already included in _next_url.\n",
    "        # This is the API access. Response is a dictionary with various keys.\n",
    "        # the .json() method decodes the response into Python object (dictionaries,\n",
    "        # lists; 'null' values are translated as None).\n",
    "        response = requests.get(self._next_url, params=parameters).json()\n",
    "        # update url so we'll fetch the next page\n",
    "        self._next_url=response['next']\n",
    "        self.count=response['count']\n",
    "        # data are in the nested 'results' list\n",
    "        return response['results'] \n",
    "\n",
    "    def get_all_pages(self, filters={}, page_size=365):\n",
    "        \"\"\" Access the API and download all available data pages of data. Sets the count\n",
    "        attribute to the total number of items available for this query. API access rate\n",
    "        limited to three request per second. The page_size parameter sets the number\n",
    "        of data points in one response page (maximum 365), and controls the trade-off\n",
    "        between time to load a page and number of pages; the default should work well \n",
    "        in most cases. The number of items returned should in any case be equal to \n",
    "        the count attribute. \"\"\"\n",
    "        data=[] # build up all data here\n",
    "        while True:\n",
    "            # use get_page to do the job, including the pacing\n",
    "            next_page=self.get_page(filters, page_size)\n",
    "            if next_page==[]:\n",
    "                break # we are done\n",
    "            data.extend(next_page)\n",
    "        return data\n",
    "# the strcuture of my API\n",
    "\n",
    "structure={\"theme\": \"infectious_disease\", \n",
    "           \"sub_theme\": \"contact\",\n",
    "           \"topic\": \"mpox-clade-2b\",\n",
    "           \"geography_type\": \"Nation\", \n",
    "           \"geography\": \"England\",\n",
    "          \"metric\": \"mpox-clade-2b_cases_countByMonth\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac249ca-0b08-4627-bf7c-59e9391ca697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644c903632c34b6e96c77a066b39a421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Refresh Data', icon='cloud-download', style=ButtonStyle(button_color=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ipywidgets as wdg\n",
    "\n",
  {
   "cell_type": "markdown",
   "id": "a6075da0-6c93-4d9e-ab17-15ac55704451",
   "metadata": {},
   "source": [
    "### Refresh Button \n",
    "\n",
    "Please press the refresh button to reload new data. \n",
   ]
  },
    "#  Lading Json at the start\n",
    "# This ensures data is available before any button is clicked\n",
    "with open(\"mpox_ukhsa_data.json\", \"rt\") as f:\n",
    "    mpox_ukhsa_data = json.load(f)\n",
    "df = pd.DataFrame(mpox_ukhsa_data)\n",
    "\n",
    "#The API access behind the load button functionality\n",
    "def access_api(button):\n",
    "    global df\n",
    "    \n",
    "    # Visual feedback to user that something is happening\n",
    "    button.description = \"Fetching...\"\n",
    "    button.icon = \"spinner\" \n",
    "    button.style.button_color = 'orange'\n",
    "    \n",
    "    try:\n",
    "        api = APIwrapper(**structure)\n",
    "        cases = api.get_all_pages()\n",
    "        \n",
    "        # If successful, supersede the pre-downloaded json data with new API data\n",
    "        df = pd.DataFrame(cases)\n",
    "        \n",
    "        # Update the load button UI to show success\n",
    "        button.description = \"Data Refreshed\"\n",
    "        button.icon = \"check\"\n",
    "        button.button_style = 'success'\n",
    "        \n",
    "    except:\n",
    "        button.description = \"API Problem\"\n",
    "        button.button_style = 'warning'\n",
    "        \n",
    "\n",
    "#Now designing and actually implementing the button \n",
    "btn_load = wdg.Button(\n",
    "    description='Refresh Data',\n",
    "    button_style='info',\n",
    "    icon='cloud-download',\n",
    "    tooltip='Click to download current data from UKHSA')\n",
    "btn_load.style.button_color = 'blue' #I wanted to make the button blue to differentiate it from the default gray  colour. \n",
    "\n",
    "# Binding the function to the button/ The link that connects the API to the button \n",
    "btn_load.on_click(access_api)\n",
    "\n",
    "# Display the button\n",
    "display(btn_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfe81d8-7b69-4a41-a278-bfb09506e88a",
   "metadata": {},
   "source": [
    "### Pie Chart for MPox 2B yearly share\n",
    "This Pie Chart shows which year saw the greatest number of MPox cases. It can be used to make long-term comparisons on a yearly basis. For e.g. it portrays that 2024 experienced the largest number of MPox cases and can be used to co-relate with other factors such as the rise in tourism in the UK in 2024 which is what caused this spike or the increase in living costs which caused cleanliness standards to depriciate and thus lead to the disease spreading quicker than before. \n",
    "\n",
    "In a nutshell, this pie chart will help analysts to develop a quick understanding of the data presented here especially in emergenecy scenarios where immediate action is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fcab1f3-b0ed-4c6b-991c-571f0cb004a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4e3396eac849b7aa5bf3d3cb1bf8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='highlight_year', options=(2023, 2024, 2025), value=2023), Output()…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_pie(highlight_year)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plotting the pie chart\n",
    "def plot_pie(highlight_year):\n",
    "    # We use the 'df' that was loaded in the previous cell\n",
    "    yearly_cases = df.groupby('year')['metric_value'].sum() \n",
    "    \n",
    "    # Explode logic (highlighting the selected slice of the pie)\n",
    "    explode = [0.1 if year == highlight_year else 0 for year in yearly_cases.index]\n",
    "\n",
    "    plt.figure(figsize=(6, 6)) # defining the size of the figure \n",
    "    yearly_cases.plot.pie(\n",
    "        y=\"metric_value\", # metric_value is the row num   \n",
    "        autopct='%1.1f%%', # includes percentage with numbers that are written on the pie chart \n",
    "        legend=False, #no legends\n",
    "        title=\"MPox 2B Yearly Share\", #title of the graph\n",
    "        colors=[\"#E0B0FF\",\"#c04657\",\"#f2b949\"], #colors of the slices in the pie\n",
    "        explode=explode) #the pop-out feature of the pie chart \n",
    "    \n",
    "    plt.ylabel(\"\")  #no title on the left of the pie chart because i didnt like the look of it so i left it blank\n",
    "    plt.show()  #printing the graph\n",
    "\n",
    "# 3. Creating dropdown options so that users can select the year \n",
    "\n",
    "years = sorted(df['year'].unique().tolist())\n",
    "\n",
    "\n",
    "# This automatically connects the dropdown and the plot together\n",
    "wdg.interact(plot_pie, highlight_year=years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6075da0-6c93-4d9e-ab17-15ac55704451",
   "metadata": {},
   "source": [
    "### Linear and Log Scale Graphs \n",
    "\n",
    "This graph helps analysts zoom in on different dates and specifically months, using both linear and log scales. \n",
    "\n",
    "I wanted to use both linear and log scales because from analysis of the graphs on the UKHSA website, I realised that most disease outbreaks (like MPox) behave differently at the beginning than they do in the middle. The log scale presents every small change very clearly. If noticed before the problem gets out of hand, medical professionals can nip it in the bud in due time. Moreover, the linear scale gives you more in depth data. It has the number of cases listed in tens on the y axis which means more cases will result in long lines that  can be used to derive conclusions in the long term and to check the number of affected people in a paticular month. \n",
    "\n",
    "Both combined together can become very powerful data analysis tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4f1c4f-9f31-41d2-b266-9db70dfda624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103d70220a2f4c0bbaf73766c908794f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(button_style='info', description='Scale:', options=('Linear', 'Log'), valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def parse_date(datestring):\n",
    "    return pd.to_datetime(datestring, format=\"%Y-%m-%d\") \n",
    "\n",
    "def plot_timeseries(scale, date_range):\n",
    "    \n",
    "    data = {} #reloading data from the  df variable\n",
    "    \n",
    "    # Iterating through the global 'df' variable which might have changed\n",
    "    for index, row in df.iterrows():\n",
    "        date = row['date']\n",
    "        metric = row['metric']\n",
    "        value = row['metric_value']\n",
    "        \n",
    "        if date not in data:\n",
    "            data[date] = {}\n",
    "        data[date][metric] = value\n",
    "\n",
    "    if not data: #creating the data frame locally, this programme will only proceed if we have the data \n",
    "        print(\"No data available to plot.\")\n",
    "        return\n",
    "\n",
    "    dates = list(data.keys())    # basically now we design the time series graph in line with the week 10 data \n",
    "    dates.sort()\n",
    "    startdate = parse_date(dates[0])\n",
    "    enddate = parse_date(dates[-1])\n",
    "\n",
    "    index = pd.date_range(startdate, enddate, freq='D')\n",
    "    timeseriesdf = pd.DataFrame(index=index, columns=['mpox_ukhsa_data'])     \n",
    "    \n",
    "    metrics = {'mpox_ukhsa_data': 'mpox-clade-2b_cases_countByMonth'}\n",
    "    \n",
    "    for date, entry in data.items(): \n",
    "        pd_date = parse_date(date)\n",
    "        col_name = 'mpox_ukhsa_data'\n",
    "        metric_name = metrics[col_name]\n",
    "        value = entry.get(metric_name, 0.0)\n",
    "        timeseriesdf.loc[pd_date, col_name] = value\n",
    "    \n",
    "    timeseriesdf.fillna(0.0, inplace=True)\n",
    "            \n",
    "    \n",
    "    plt.figure(figsize=(10, 5)) # plotting the time series graph \n",
    "    \n",
    "    \n",
    "    # The slider returns simple timestamps; we need to ensure format matches\n",
    "    start_input, end_input = date_range\n",
    "    \n",
    "    mask = (timeseriesdf.index >= start_input) & (timeseriesdf.index <= end_input) # the index contains all the data in the data frame \n",
    "    filtered_df = timeseriesdf.loc[mask]  #putting the mask in the loc so that Pandas only keeps the row where the condition for the mask stands true \n",
    "\n",
    "    # Logic for scale\n",
    "    if scale == 'Log': \n",
    "        plt.yscale('log')\n",
    "        title_scale = \" (Log Scale)\"\n",
    "    else:\n",
    "        plt.yscale('linear') \n",
    "        title_scale = \" (Linear Scale)\"\n",
    "        \n",
    "    plt.plot(filtered_df.index, filtered_df['mpox_ukhsa_data'], color='#702963') \n",
    "    plt.title(f\"MPox UKHSA Data Over Time{title_scale}\") \n",
    "    plt.xlabel(\"Date\") \n",
    "    plt.ylabel(\"Cases\") \n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Adding a 'dummy' timeseriesdf to get the min/max dates for the slider \n",
    "dates_sorted = pd.to_datetime(df['date']).sort_values()\n",
    "\n",
    "dt_options = []\n",
    "for date in dates_sorted:\n",
    "    label = date.strftime('%d %b %Y')\n",
    "    value = date\n",
    "    pair = (label, value)\n",
    "    dt_options.append(pair)\n",
    "\n",
    "scale_widget = wdg.ToggleButtons(\n",
    "    options=['Linear', 'Log'],\n",
    "    description='Scale:',\n",
    "    button_style='info')\n",
    "\n",
    "date_slider = wdg.SelectionRangeSlider(\n",
    "    options=dt_options,\n",
    "    index=(0, len(dt_options)-1), \n",
    "    description='Dates:',\n",
    "    orientation='horizontal',\n",
    "    layout={'width': '500px'})\n",
    "\n",
    "wdg.interact(plot_timeseries, scale=scale_widget, date_range=date_slider);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af4cea8-bbeb-4959-abd5-dc37d92199f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c03fe7-cca6-4c06-b814-586f44f7e4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e99850-646e-40ed-af3d-d6dd1837d82f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
